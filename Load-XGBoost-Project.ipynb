{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc67fe2",
   "metadata": {},
   "source": [
    "# Download dependencies/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c17ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    17    0    17    0     0     57      0 --:--:-- --:--:-- --:--:--    57\n",
      "100   340  100   340    0     0    478      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   534    0   534    0     0    425      0 --:--:--  0:00:01 --:--:--   425\n",
      " 41  515M   41  212M    0     0  46.1M      0  0:00:11  0:00:04  0:00:07 70.7M^C\n",
      "Archive:  kaggle-download.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "unzip:  cannot find zipfile directory in one of kaggle-download.zip or\n",
      "        kaggle-download.zip.zip, and cannot find kaggle-download.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://www.dropbox.com/s/rndzndlgpw3coiq/kaggle-download.zip -o kaggle-download.zip\n",
    "!unzip kaggle-download.zip -d kaggle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3665813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "818534c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 14.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from hyperopt) (1.22.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.9/site-packages (from hyperopt) (1.7.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.9/site-packages (from hyperopt) (1.6.0)\n",
      "Collecting future\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[K     |████████████████████████████████| 840 kB 57.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.9/site-packages (from hyperopt) (2.5)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from hyperopt) (4.61.2)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 53.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.9/site-packages (from networkx>=2.2->hyperopt) (5.0.9)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492026 sha256=ec372d44630e94bb8052c2a3a28630c7890d98d786025dd7107cdf093e6684fb\n",
      "  Stored in directory: /home/acz001/.cache/pip/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built future\n",
      "Installing collected packages: py4j, future, hyperopt\n",
      "\u001b[33m  WARNING: The scripts futurize and pasteurize are installed in '/home/acz001/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script hyperopt-mongo-worker is installed in '/home/acz001/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed future-0.18.3 hyperopt-0.2.7 py4j-0.10.9.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5411bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import xgboost\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefdeef9",
   "metadata": {},
   "source": [
    "# Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c73b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_data = pd.read_csv(\"kaggle_data/metaData_taxistandsID_name_GPSlocation.csv\")\n",
    "# The following code normalizes longitudes and latitudes.\n",
    "# df_taxi_data[\"Longitude\"] = (df_taxi_data[\"Longitude\"] - df_taxi_data[\"Longitude\"].mean()) / df_taxi_data[\"Longitude\"].std()\n",
    "# df_taxi_data[\"Latitude\"] = (df_taxi_data[\"Latitude\"] - df_taxi_data[\"Latitude\"].mean()) / df_taxi_data[\"Latitude\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a056e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "def process_df(df):\n",
    "    def parse_time(x):\n",
    "        # We are using python's builtin datetime library\n",
    "        # https://docs.python.org/3/library/datetime.html#datetime.date.fromtimestamp\n",
    "\n",
    "        # Each x is essentially a 1 row, 1 column pandas Series\n",
    "        dt = datetime.fromtimestamp(x[\"TIMESTAMP\"])\n",
    "        return dt.year, dt.month, dt.day, dt.hour, dt.weekday()\n",
    "\n",
    "    def get_lat_long(x):\n",
    "        if math.isnan(x[\"ORIGIN_STAND\"]):\n",
    "            return 0, 0\n",
    "        taxi_row = df_taxi_data.iloc[int(x[\"ORIGIN_STAND\"]) - 1]\n",
    "        return float(taxi_row[\"Latitude\"]), float(taxi_row[\"Longitude\"])\n",
    "    \n",
    "    def augment_lat_long(df):\n",
    "        if \"POLYLINE\" not in df:\n",
    "            return df\n",
    "        augmented_df = []\n",
    "        for i, row in df.iterrows():\n",
    "            if math.isnan(row[\"ORIGIN_STAND\"]):\n",
    "                    start = [i.replace(']', '').replace('[', '').split(',') for i in row[\"POLYLINE\"].split('],')][0]\n",
    "                    if len(start) == 2:\n",
    "                        row.LATITUDE = float(start[0])\n",
    "                        row.LONGITUDE = float(start[1])\n",
    "                        augmented_df.append(row)\n",
    "        return pd.concat([df, pd.DataFrame(augmented_df, columns=df.columns)], ignore_index=True)\n",
    "\n",
    "    df[[\"LATITUDE\", \"LONGITUDE\"]] = df.apply(get_lat_long, axis=1, result_type=\"expand\")\n",
    "    df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
    "    #df = augment_lat_long(df)\n",
    "    df.drop(['TRIP_ID', \"POLYLINE\", 'MISSING_DATA', 'TAXI_ID', 'DAY_TYPE'], axis=1, inplace=True, errors=\"ignore\")\n",
    "    \n",
    "    categorical_cols = ['CALL_TYPE', 'ORIGIN_CALL', 'ORIGIN_STAND', 'YR', 'MON', 'DAY', 'HR', 'WK']\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    if 'LEN' in df.columns:\n",
    "        df['LEN'] = df['LEN'].astype('float64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b46b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows_removed=10\n"
     ]
    }
   ],
   "source": [
    "# These are all of the files you are given\n",
    "original_df_tr = pd.read_csv(\"kaggle_data/train.csv\")\n",
    "\n",
    "# getting rid of incomplete rows\n",
    "original_rows = original_df_tr.shape[0]\n",
    "\n",
    "df_tr = original_df_tr.loc[original_df_tr['MISSING_DATA'] == False]\n",
    "\n",
    "rows_removed = original_rows - df_tr.shape[0]\n",
    "print(f\"{rows_removed=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e7e19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5873/3024709668.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_tr[\"LEN\"] = df_tr[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
      "/tmp/ipykernel_5873/2434493553.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"LATITUDE\", \"LONGITUDE\"]] = df.apply(get_lat_long, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"LATITUDE\", \"LONGITUDE\"]] = df.apply(get_lat_long, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[[\"YR\", \"MON\", \"DAY\", \"HR\", \"WK\"]] = df.apply(parse_time, axis=1, result_type=\"expand\")\n",
      "/tmp/ipykernel_5873/2434493553.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['TRIP_ID', \"POLYLINE\", 'MISSING_DATA', 'TAXI_ID', 'DAY_TYPE'], axis=1, inplace=True, errors=\"ignore\")\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype('category')\n",
      "/tmp/ipykernel_5873/2434493553.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['LEN'] = df['LEN'].astype('float64')\n"
     ]
    }
   ],
   "source": [
    "def polyline_to_trip_duration(polyline):\n",
    "    return max(polyline.count(\"[\") - 2, 0) * 15\n",
    "\n",
    "# This code creates a new column, \"LEN\", in our dataframe. The value is\n",
    "# the (polyline_length - 1) * 15, where polyline_length = count(\"[\") - 1\n",
    "df_tr[\"LEN\"] = df_tr[\"POLYLINE\"].apply(polyline_to_trip_duration)\n",
    "\n",
    "df_tr = process_df(df_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53595b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mean = df_tr['LEN'].mean()\n",
    "len_std = df_tr['LEN'].std()\n",
    "len_range = (len_mean - 3 * len_std, len_mean + 3 * len_std)\n",
    "df_tr = df_tr.loc[df_tr['LEN'] < len_mean + 3 * len_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad176d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_tr.drop('LEN', axis=1)\n",
    "y = df_tr['LEN']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c4f11",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e5dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f2b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all of the files you are given\n",
    "# Writing the output to submit to kaggle\n",
    "df_test = pd.read_csv(\"kaggle_data/test_public.csv\")\n",
    "titles = df_test['TRIP_ID']\n",
    "df_test = process_df(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26af646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.Booster()\n",
    "model.load_model('model.json')\n",
    "X_submission = df_test\n",
    "dsubmission_reg = xgb.DMatrix(X_submission, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "131e58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(dsubmission_reg)\n",
    "df = pd.DataFrame(data={\"TRIP_ID\": titles, \"TRAVEL_TIME\": predictions})\n",
    "df.to_csv(\"solution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad757e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
